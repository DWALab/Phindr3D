# Copyright (C) 2022 Sunnybrook Research Institute
# This file is part of src <https://github.com/DWALab/Phindr3D>.
#
# src is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# src is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with src.  If not, see <http://www.gnu.org/licenses/>.
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA, KernelPCA
from sklearn.preprocessing import StandardScaler
from scipy.spatial.distance import cdist
import numpy as np

class Clustering:
    """Not sure what this class is for yet"""

    def __init__(self):
        """ClusterStuff constructor"""
        pass

# end class ClusterStuff
def plot_type(X, dim, plot):
    # SAMMON MAPPING FUNCTION (not used)
    def cmdscale(D):
        # copied from https://github.com/tompollard/sammon as no other python libraries appear to have implemented sammon mapping.

        """
        Classical multidimensional scaling (MDS)

        Parameters
        ----------
        D : (n, n) array
            Symmetric distance matrix.

        Returns
        -------
        Y : (n, p) array
            Configuration matrix. Each column represents a dimension. Only the
            p dimensions corresponding to positive eigenvalues of B are returned.
            Note that each dimension is only determined up to an overall sign,
            corresponding to a reflection.

        e : (n,) array
            Eigenvalues of B.

        """
        # Number of points
        n = len(D)

        # Centering matrix
        H = np.eye(n) - np.ones((n, n)) / n

        # YY^T
        B = -H.dot(D ** 2).dot(H) / 2

        # Diagonalize
        evals, evecs = np.linalg.eigh(B)

        # Sort by eigenvalue in descending order
        idx = np.argsort(evals)[::-1]
        evals = evals[idx]
        evecs = evecs[:, idx]

        # Compute the coordinates using positive-eigenvalued components only
        w, = np.where(evals > 0)
        L = np.diag(np.sqrt(evals[w]))
        V = evecs[:, w]
        Y = V.dot(L)

        return Y, evals[evals > 0]


    def rescale(x, newmin=0, newmax=1):
        """
        This function linearly rescales an array to the range [newmin, newmax]
        :param x:, numpy array, to be rescaled
        :param newmin: float, minimum value in new range
        :param newmax: float, maximum value in new range

        :return: x rescaled.
        """
        minx = np.min(x)
        maxx = np.max(x)
        return (x - minx) / (maxx - minx) * (newmax - newmin) + newmin

    def sammon(x, n, display=0, inputdist='raw', maxhalves=20, maxiter=500, tolfun=1e-9, init='default'):
        # copied from https://github.com/tompollard/sammon as no other python libraries appear to have implemented sammon mapping.
        # this appears to be the same implementation as is used in matlab's drtoolbox.



        """Perform Sammon mapping on dataset x
        y = sammon(x) applies the Sammon nonlinear mapping procedure on
        multivariate data x, where each row represents a pattern and each column
        represents a feature.  On completion, y contains the corresponding
        co-ordinates of each point on the map.  By default, a two-dimensional
        map is created.  Note if x contains any duplicated rows, SAMMON will
        fail (ungracefully).
        [y,E] = sammon(x) also returns the value of the cost function in E (i.e.
        the stress of the mapping).
        An N-dimensional output map is generated by y = sammon(x,n) .
        A set of optimisation options can be specified using optional
        arguments, y = sammon(x,n,[OPTS]):
           maxiter        - maximum number of iterations
           tolfun         - relative tolerance on objective function
           maxhalves      - maximum number of step halvings
           input          - {'raw','distance'} if set to 'distance', X is
                            interpreted as a matrix of pairwise distances.
           display        - 0 to 2. 0 least verbose, 2 max verbose.
           init           - {'pca', 'cmdscale', random', 'default'}
                            default is 'pca' if input is 'raw',
                            'msdcale' if input is 'distance'
        The default options are retrieved by calling sammon(x) with no
        parameters.
        File        : sammon.py
        Date        : 18 April 2014
        Authors     : Tom J. Pollard (tom.pollard.11@ucl.ac.uk)
                    : Ported from MATLAB implementation by
                      Gavin C. Cawley and Nicola L. C. Talbot
        Description : Simple python implementation of Sammon's non-linear
                      mapping algorithm [1].
        References  : [1] Sammon, John W. Jr., "A Nonlinear Mapping for Data
                      Structure Analysis", IEEE Transactions on Computers,
                      vol. C-18, no. 5, pp 401-409, May 1969.
        Copyright   : (c) Dr Gavin C. Cawley, November 2007.
        This program is free software; you can redistribute it and/or modify
        it under the terms of the GNU General Public License as published by
        the Free Software Foundation; either version 2 of the License, or
        (at your option) any later version.
        This program is distributed in the hope that it will be useful,
        but WITHOUT ANY WARRANTY; without even the implied warranty of
        MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
        GNU General Public License for more details.
        You should have received a copy of the GNU General Public License
        along with this program; if not, write to the Free Software
        Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
        """

        # Create distance matrix unless given by parameters
        if x.shape[0] > 10000:
            raise ValueError("should be a memory error actually: input array too big, would cause memory error")
        if inputdist == 'distance':
            D = x
            if init == 'default':
                init = 'cmdscale'
        else:
            D = cdist(x, x)
            if init == 'default':
                init = 'pca'

        if inputdist == 'distance' and init == 'pca':
            raise ValueError("Cannot use init == 'pca' when inputdist == 'distance'")

        if np.count_nonzero(np.diagonal(D)) > 0:
            raise ValueError("The diagonal of the dissimilarity matrix must be zero")

        # Remaining initialisation
        N = x.shape[0]
        scale = 0.5 / D.sum()
        D = D + np.eye(N)

        if np.count_nonzero(D <= 0) > 0:
            raise ValueError("Off-diagonal dissimilarities must be strictly positive")

        Dinv = 1 / D
        if init == 'pca':
            [UU, DD, _] = np.linalg.svd(x)
            y = UU[:, :n] * DD[:n]
        elif init == 'cmdscale':
            y, e = cmdscale(D)
            y = y[:, :n]
        else:
            y = np.random.normal(0.0, 1.0, [N, n])
        one = np.ones([N, n])
        d = cdist(y, y) + np.eye(N)
        dinv = 1. / d
        delta = D - d
        E = ((delta ** 2) * Dinv).sum()

        # Get on with it
        for i in range(maxiter):

            # Compute gradient, Hessian and search direction (note it is actually
            # 1/4 of the gradient and Hessian, but the step size is just the ratio
            # of the gradient and the diagonal of the Hessian so it doesn't
            # matter).
            delta = dinv - Dinv
            deltaone = np.dot(delta, one)
            g = np.dot(delta, y) - (y * deltaone)
            dinv3 = dinv ** 3
            y2 = y ** 2
            H = np.dot(dinv3, y2) - deltaone - np.dot(2, y) * np.dot(dinv3, y) + y2 * np.dot(dinv3, one)
            s = -g.flatten(order='F') / np.abs(H.flatten(order='F'))
            y_old = y

            # Use step-halving procedure to ensure progress is made
            for j in range(maxhalves):
                s_reshape = np.reshape(s, (-1, n), order='F')
                y = y_old + s_reshape
                d = cdist(y, y) + np.eye(N)
                dinv = 1 / d
                delta = D - d
                E_new = ((delta ** 2) * Dinv).sum()
                if E_new < E:
                    break
                else:
                    s = 0.5 * s

            # Bomb out if too many halving steps are required
            if j == maxhalves - 1:
                print('Warning: maxhalves exceeded. Sammon mapping may not converge...')

            # Evaluate termination criterion
            if abs((E - E_new) / E) < tolfun:
                if display:
                    print('TolFun exceeded: Optimisation terminated')
                break

            # Report progress
            E = E_new
            if display > 1:
                print('epoch = %d : E = %12.10f' % (i + 1, E * scale))

        if i == maxiter - 1:
            print('Warning: maxiter exceeded. Sammon mapping may not have converged...')

        # Fiddle stress to match the original Sammon paper
        E = E * scale

        return [y, E]

    if plot=="PCA":
        func='linear'
        sc = StandardScaler()
        X_show = sc.fit_transform(X)
        pca = KernelPCA(n_components=dim, kernel=func)
        P = pca.fit(X_show).transform(X_show)
        return('PCA plot', 'PCA 1', 'PCA 2', P)
    elif plot =="t-SNE":
        T = TSNE(n_components=dim, init='pca', learning_rate='auto').fit_transform(X)
        return('t-SNE plot', 't-SNE 1', 't-SNE 2', T)
    elif plot =="Sammon":
        S, E = sammon(X, dim)
        return('Sammon plot', 'Sammon 1', 'Sammon 2', S)
    else:
        raise Exception("Invalid plot")

if __name__ == '__main__':
    """Not sure what this will do yet"""

    pass





# end main